{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anujsahani01/EngMarBART/blob/main/Bidirectional(en_mr).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p9-kSLAM1nZS"
      },
      "outputs": [],
      "source": [
        "# !pip install datasets\n",
        "# !pip install --upgrade accelerate\n",
        "# !pip install wandb\n",
        "# !pip install --no-cache-dir transformers sentencepiece\n",
        "# !pip install evaluate\n",
        "# !pip install rouge_score\n",
        "# !pip install sacremoses\n",
        "# !pip install fasttext\n",
        "# !pip install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dUITVkqM6nBw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from huggingface_hub import notebook_login\n",
        "# notebook_login()"
      ],
      "metadata": {
        "id": "QDLP91id6nSl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !huggingface-cli login"
      ],
      "metadata": {
        "id": "jOHNlZy56nVb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset('anujsahani01/processed_en_mr')"
      ],
      "metadata": {
        "id": "4XbV0Nhp_4Db"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ryHa0nC_2uf",
        "outputId": "568e472f-e388-4b30-8e37-77b4fae1151c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    test: Dataset({\n",
              "        features: ['english', 'marathi'],\n",
              "        num_rows: 77723\n",
              "    })\n",
              "    train: Dataset({\n",
              "        features: ['english', 'marathi'],\n",
              "        num_rows: 310890\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50\", src_lang=\"en_XX\", tgt_lang=\"mr_IN\", model_max_length = 512)\n",
        "tokenizer.bos_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "b67cBgqy6oB-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer"
      ],
      "metadata": {
        "id": "jcYFH8mA6oSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c965ce3e-eeb1-402d-94e2-4ede0da6d288"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MBart50TokenizerFast(name_or_path='facebook/mbart-large-50', vocab_size=250054, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>', 'additional_special_tokens': ['ar_AR', 'cs_CZ', 'de_DE', 'en_XX', 'es_XX', 'et_EE', 'fi_FI', 'fr_XX', 'gu_IN', 'hi_IN', 'it_IT', 'ja_XX', 'kk_KZ', 'ko_KR', 'lt_LT', 'lv_LV', 'my_MM', 'ne_NP', 'nl_XX', 'ro_RO', 'ru_RU', 'si_LK', 'tr_TR', 'vi_VN', 'zh_CN', 'af_ZA', 'az_AZ', 'bn_IN', 'fa_IR', 'he_IL', 'hr_HR', 'id_ID', 'ka_GE', 'km_KH', 'mk_MK', 'ml_IN', 'mn_MN', 'mr_IN', 'pl_PL', 'ps_AF', 'pt_XX', 'sv_SE', 'sw_KE', 'ta_IN', 'te_IN', 'th_TH', 'tl_XX', 'uk_UA', 'ur_PK', 'xh_ZA', 'gl_ES', 'sl_SI']}, clean_up_tokenization_spaces=True)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "special_tokens_dict = {\"eos_token\": \"<CLS>\"}\n",
        "\n",
        "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "print(\"We have added\", num_added_toks, \"tokens\")"
      ],
      "metadata": {
        "id": "ik0a00qe6oVm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14da01d-85e5-4d58-aa2c-33e26479ca91"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have added 1 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = tokenizer(dataset['train']['english'][0], text_target =  dataset['train']['marathi'][0],  max_length= 100, padding = 'max_length', truncation=True, return_length = True, return_tensors = 'pt')"
      ],
      "metadata": {
        "id": "E3yKwDgs6oYX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(out['input_ids'][0])"
      ],
      "metadata": {
        "id": "-jhksnIy6oa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39e1aa19-1fbe-4fc1-9668-354cb971b4c6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_preds = tokenizer.batch_decode(out['input_ids'])\n",
        "print(decoded_preds)"
      ],
      "metadata": {
        "id": "8EHLNrXX6odX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1984129b-a341-4b47-ccf4-1562030a9bf8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['en_XX Besides Aamir Khan, the film also stars Amitabh Bachchan, Katrina Kaif and Fatima Sana Shaikh in the lead roles Meanwhile, Operation Shakti was also launched in Lucknow to tackle crimes against women in the state On being informed about the incident, police reached the spot and seized the body PM then decided to undertake an aerial survey of flood affected areas of North Gujarat this afternoon, after the swearingin ce<CLS>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.batch_decode(out['labels'])"
      ],
      "metadata": {
        "id": "Z6FGtWXe6ofn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49698b6b-86f8-4e53-c287-17ae766814c2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"mr_IN दिवाळीच्या मुहुर्तावर प्रेक्षकांच्या भेटीला येणाऱ्या या चित्रपटामध्ये आमिर खान आणि अमिताभ बच्चन यांच्यासह कतरिना कैफ, फातिमा सना शेख यांच्याही प्रमुख भूमिका आहेत. दुसरीकडे, उत्तर प्रदेशची राजधानी असलेल्या लखनौ शहरात महिलावर होणाऱ्या अत्याचाराविरोधात 'ऑपरेशन शक्ति' अभियान सुरू करण्यात आलं आहे. घटनेची माहिती मिळताच पोलीस घटनास्थळी दाखल झाले आणि त्यांची मुलीचं शव ताब्यात घेतलं. नवीन राष्ट्रपती<CLS>\"]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "a7FEnGUf6oiL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 85\n",
        "context_length = 85\n",
        "\n",
        "def tokenize(data):\n",
        "  data = tokenizer(data['english'], text_target =  data['marathi'],  max_length= max_length, padding = 'max_length', truncation=True, return_length = True, return_tensors = 'pt')\n",
        "  inp_ids = []\n",
        "  if len(data['input_ids']) != 0:\n",
        "    for length, ids in zip(data[\"length\"], data[\"input_ids\"]):\n",
        "      inp_ids.append(ids)\n",
        "    label = []\n",
        "    for length, lb in zip(data[\"length\"], data[\"labels\"]):\n",
        "      label.append(lb)\n",
        "\n",
        "\n",
        "  return {\"input_ids\": inp_ids,\n",
        "          'labels' : label}"
      ],
      "metadata": {
        "id": "Qq3xzaRVYKnE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = dataset.map(\n",
        "    tokenize,\n",
        "    batched=True,\n",
        "    remove_columns =  dataset[\"train\"].column_names,\n",
        ")"
      ],
      "metadata": {
        "id": "aD-Q3r8TYKqa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "EXws_p7DYKts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65404dce-b373-48b8-893e-07ddfee61d41"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'labels'],\n",
              "        num_rows: 77723\n",
              "    })\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'labels'],\n",
              "        num_rows: 310890\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp = tokenized_dataset['train']['input_ids']"
      ],
      "metadata": {
        "id": "5PU7i1WoYKwq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr = []\n",
        "import pandas as pd\n",
        "df_final = pd.DataFrame()\n",
        "df_final['tokenized_eng'] = inp"
      ],
      "metadata": {
        "id": "DUMufj6tYKz7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final['length'] = df_final['tokenized_eng'].apply(\n",
        "    lambda row: len(row)\n",
        ")"
      ],
      "metadata": {
        "id": "i5rAwRZ8YK24"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_final['length'].min())\n",
        "print(df_final['length'].max())\n",
        "print(df_final['length'].min())"
      ],
      "metadata": {
        "id": "vle-KAuGYK5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dc7f42b-02aa-4acc-b6c6-dfcdd8a4fccf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85\n",
            "85\n",
            "85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U neptune transformers"
      ],
      "metadata": {
        "id": "UUi-zCcHYK8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9ed23a4-c3c5-43ea-fcb6-c818f07d7b70"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: neptune in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: GitPython>=2.0.8 in /usr/local/lib/python3.10/dist-packages (from neptune) (3.1.32)\n",
            "Requirement already satisfied: Pillow>=1.1.6 in /usr/local/lib/python3.10/dist-packages (from neptune) (9.4.0)\n",
            "Requirement already satisfied: PyJWT in /usr/lib/python3/dist-packages (from neptune) (2.3.0)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from neptune) (2.2.1)\n",
            "Requirement already satisfied: boto3>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from neptune) (1.28.20)\n",
            "Requirement already satisfied: bravado<12.0.0,>=11.0.0 in /usr/local/lib/python3.10/dist-packages (from neptune) (11.0.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from neptune) (8.1.6)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from neptune) (0.18.3)\n",
            "Requirement already satisfied: oauthlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from neptune) (3.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from neptune) (23.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from neptune) (1.5.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from neptune) (5.9.5)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from neptune) (2.27.1)\n",
            "Requirement already satisfied: requests-oauthlib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from neptune) (1.3.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from neptune) (1.16.0)\n",
            "Requirement already satisfied: swagger-spec-validator>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from neptune) (3.0.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from neptune) (1.26.16)\n",
            "Requirement already satisfied: websocket-client!=1.0.0,>=0.35.0 in /usr/local/lib/python3.10/dist-packages (from neptune) (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: botocore<1.32.0,>=1.31.20 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.16.0->neptune) (1.31.20)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.16.0->neptune) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.16.0->neptune) (0.6.1)\n",
            "Requirement already satisfied: bravado-core>=5.16.1 in /usr/local/lib/python3.10/dist-packages (from bravado<12.0.0,>=11.0.0->neptune) (6.1.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from bravado<12.0.0,>=11.0.0->neptune) (1.0.5)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from bravado<12.0.0,>=11.0.0->neptune) (2.8.2)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.10/dist-packages (from bravado<12.0.0,>=11.0.0->neptune) (3.19.1)\n",
            "Requirement already satisfied: monotonic in /usr/local/lib/python3.10/dist-packages (from bravado<12.0.0,>=11.0.0->neptune) (1.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from bravado<12.0.0,>=11.0.0->neptune) (4.7.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython>=2.0.8->neptune) (4.0.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->neptune) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->neptune) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->neptune) (3.4)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from swagger-spec-validator>=2.7.4->neptune) (4.3.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->neptune) (2022.7.1)\n",
            "Requirement already satisfied: jsonref in /usr/local/lib/python3.10/dist-packages (from bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune) (1.1.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython>=2.0.8->neptune) (5.0.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (0.19.3)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.10/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.10/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.10/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (2.4)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.10/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (0.1.4)\n",
            "Requirement already satisfied: rfc3987 in /usr/local/lib/python3.10/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (1.3.8)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.10/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=1.11 in /usr/local/lib/python3.10/dist-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune) (1.13)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from isoduration->jsonschema->swagger-spec-validator>=2.7.4->neptune) (1.2.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "from transformers.integrations import NeptuneCallback\n",
        "import neptune"
      ],
      "metadata": {
        "id": "9xx8lZIiYK-_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_project = \"anujsahani01/ITStudio\"\n",
        "run = neptune.init_run(\n",
        "    project=\"anujsahani01/ITStudio\",\n",
        "    api_token = 'eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJkMzNmZWY5My0yOGY1LTRiZDItODA1MS05ZTM3MTc0MTI2NTYifQ==',\n",
        "    source_files= [\"/content/drive/MyDrive/Mbart(Finetuning).ipynb\"]\n",
        ")\n",
        "\n",
        "\n",
        "neptune_callback = NeptuneCallback(run=run)\n",
        "# run[\"train_dataset\"].track_files(\"./train.csv\")\n"
      ],
      "metadata": {
        "id": "N_n9WIAvYLB3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be338c4-c441-47aa-9666-9b2ea6ac1711"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-b6d931fdc011>:2: NeptuneWarning: To avoid unintended consumption of logging hours during interactive sessions, the following monitoring options are disabled unless set to 'True' when initializing the run: 'capture_stdout', 'capture_stderr', and 'capture_hardware_metrics'.\n",
            "  run = neptune.init_run(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/anujsahani01/ITStudio/e/MODEL-77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoConfig\n",
        "model_checkpoint  = \"facebook/mbart-large-50\"\n",
        "config = AutoConfig.from_pretrained(model_checkpoint, vocab_size=len(tokenizer), use_auth_token=True,)\n",
        "\n",
        "config.vocab_size = tokenizer.vocab_size\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint, config = config, ignore_mismatched_sizes=True).to('cuda')\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "id": "VPwYn6FEYLEq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f33cbff-1043-4262-830a-45e48d5e9ed4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(250055, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "metadata": {
        "id": "Xki7L565YLHQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install evaluate"
      ],
      "metadata": {
        "id": "wx_TBu0_Yw9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f01f92b-8fe8-4c3b-8d03-bc1372d41f5f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.14.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.22.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2022.7.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "metric = evaluate.load(\"sacrebleu\")"
      ],
      "metadata": {
        "id": "zvFxujTuYxAe"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "  preds, labels = eval_preds\n",
        "  # In case the model returns more than the prediction logits\n",
        "  if isinstance(preds, tuple):\n",
        "      preds = preds[0]\n",
        "\n",
        "  decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "  # Replace -100s in the labels as we can't decode them\n",
        "  labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "  # Some simple post-processing\n",
        "  decoded_preds = [pred.strip() for pred in decoded_preds]\n",
        "  decoded_labels = [[label.strip()] for label in decoded_labels]\n",
        "\n",
        "  result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "  return {\"bleu\": result[\"score\"]}"
      ],
      "metadata": {
        "id": "L5t4Y4T9YxDK"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qjE1r0BKNO52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'lr':0.0005, 'max_steps': 9000, 'warmup_steps': 30, 'weight_decay': 0.1, 'per_device_train_batch_size': 9, 'per_device_eval_batch_size':9, 'evaluation_strategy' :\"no\", 'save_total_limit' :1, 'num_train_epochs': 1, 'predict_with_generate' : True, 'fp16' : False, 'push_to_hub' : True, 'remove_unused_columns' :False}"
      ],
      "metadata": {
        "id": "gF7nQAN-YxGC"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    f\"./finetuned_en2mr\",\n",
        "    evaluation_strategy= params['evaluation_strategy'],\n",
        "    # eval_steps=1500,\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate= params['lr'] ,\n",
        "    per_device_train_batch_size=params['per_device_train_batch_size'],\n",
        "    per_device_eval_batch_size= params['per_device_eval_batch_size'],\n",
        "    warmup_steps = params['warmup_steps'],\n",
        "    weight_decay= params['weight_decay'],\n",
        "    save_total_limit= params['save_total_limit'],\n",
        "    num_train_epochs= params['num_train_epochs'],\n",
        "    predict_with_generate= params['predict_with_generate'],\n",
        "    fp16= params['fp16'],\n",
        "    push_to_hub= params['push_to_hub'],\n",
        "    max_steps = params['max_steps'],\n",
        "    remove_unused_columns= params['remove_unused_columns'],\n",
        "    report_to=\"neptune\"\n",
        "    # predict_with_generate = True\n",
        ")"
      ],
      "metadata": {
        "id": "YoDVF3nbYxIm"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neptune_callback = NeptuneCallback(run=run)"
      ],
      "metadata": {
        "id": "ItwyQTUSYxLn"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model.to('cuda'),\n",
        "    args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics)\n",
        "    # callbacks=[neptune_callback])"
      ],
      "metadata": {
        "id": "rxe7g0CTYxOL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a4d8f95-6403-4e63-fcc6-7c36c3c68840"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/./finetuned_en2mr is already a clone of https://huggingface.co/anujsahani01/finetuned_en2mr. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:/content/./finetuned_en2mr is already a clone of https://huggingface.co/anujsahani01/finetuned_en2mr. Make sure you pull the latest changes with `repo.git_pull()`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for cb in trainer.callback_handler.callbacks:\n",
        "  if isinstance(cb, NeptuneCallback):\n",
        "    trainer.callback_handler.remove_callback(cb)"
      ],
      "metadata": {
        "id": "Cw6SJY2CYxRG"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "ky1JHs78YLJ2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "899832fc-805d-439d-a8c1-b648d2124547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "You're using a MBart50TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2557' max='9000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2557/9000 48:15 < 2:01:41, 0.88 it/s, Epoch 0.07/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>5.817300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>4.482400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>4.189100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>4.048300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>3.886500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = trainer.state.log_history"
      ],
      "metadata": {
        "id": "lQZIPwrSY9YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in params.items():\n",
        "  run[key] = value"
      ],
      "metadata": {
        "id": "bPVkn39PY9er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = []\n",
        "train_loss = []\n",
        "steps =  []\n",
        "epoch = []"
      ],
      "metadata": {
        "id": "51bVs3c4Y9hK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(metrics)-1):\n",
        "  train_loss.append(metrics[i]['loss'])\n",
        "  steps.append(metrics[i]['step'])\n",
        "  lr.append(metrics[i]['learning_rate'])\n",
        "  epoch.append(metrics[i]['epoch'])"
      ],
      "metadata": {
        "id": "Iw3rNa_qY9j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train_loss)):\n",
        "  run['train/loss'].append(train_loss[i])\n",
        "\n",
        "for i in range(len(epoch)):\n",
        "  run['epoch'].append(epoch[i])\n",
        "\n",
        "for i in range(len(lr)):\n",
        "  run[\"learning_rate\"].append(lr[i])\n",
        "\n",
        "for i in range(len(steps)):\n",
        "  run[\"steps\"].append(steps[i])"
      ],
      "metadata": {
        "id": "4IVugZ7iZCgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub()"
      ],
      "metadata": {
        "id": "0oOj2Ei-ZCkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install sacremoses"
      ],
      "metadata": {
        "id": "59Z7doIaZCmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, TranslationPipeline, Text2TextGenerationPipeline, pipeline\n",
        "\n",
        "model_ckpt = \"anujsahani01/finetuned_en2mr\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt)\n",
        "pipe = pipeline('translation_en_to_mr', model_ckpt)"
      ],
      "metadata": {
        "id": "3c8cfsJ2ZLX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_text = 'he is playing outside'\n",
        "pred = pipe(src_text, num_return_sequences=3)\n",
        "pred"
      ],
      "metadata": {
        "id": "1A1x7fljnB9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run[\"train_dataset\"].track_files(\"./train.csv\")"
      ],
      "metadata": {
        "id": "MZk75PynnCEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import TranslationEvaluator\n",
        "metric = TranslationEvaluator(task = 'translation', default_metric_name = \"bleu\")\n",
        "evaluation_results = metric.compute(model_or_pipeline = model, tokenizer = tokenizer,  metric = 'bleu', data = dataset['test'][:100] , device = 0, split = 'test' ,input_column = 'english', label_column = 'marathi')"
      ],
      "metadata": {
        "id": "US5NfjWCnCI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run[\"bleu\"].append(evaluation_results[\"bleu\"])"
      ],
      "metadata": {
        "id": "uZ8n25xInCNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run.stop()"
      ],
      "metadata": {
        "id": "JgoLQoFSnCTG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}